{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import joblib\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from model import CINN\n",
    "from plot_utils import (\n",
    "    load_model_and_data,\n",
    "    sample_posteriors,\n",
    "    compute_map_estimates,\n",
    "    build_priors_from_training,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_fname(fname):\n",
    "    base = os.path.splitext(os.path.basename(fname))[0]\n",
    "    import re\n",
    "    m = re.match(r\"^snap_(\\d+)_halo_(\\d+)_proj_(\\d+)$\", base)\n",
    "    if not m:\n",
    "        raise ValueError(f\"Unexpected filename: {base}\")\n",
    "    snap, halo, proj = map(int, m.groups())\n",
    "    return f\"{halo}_{snap}_{proj}\"\n",
    "\n",
    "def plot_figure14_new_pipeline(\n",
    "    model_checkpoint: str,\n",
    "    params_path: str,\n",
    "    processed_dir: str = \"processed_data\",\n",
    "    emb_path: str = \"embeddings.npy\",\n",
    "    fname_path: str = \"filenames.npy\",\n",
    "    n_rows: int = 10,\n",
    "    n_samples: int = 600,\n",
    "    random_state: int = 42,\n",
    "    select_halo_ids: list = None,\n",
    "    select_snapshots: list = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Rewritten to use the new pipeline (embeddings → cINN → features),\n",
    "    with column titles on the first row and, on the last row,\n",
    "    numeric x‐axis ticks (5 evenly spaced) plus a two‐line label\n",
    "    (name on the first line, unit on the second). All other rows hide x‐ticks.\n",
    "    \"\"\"\n",
    "\n",
    "    # ─── 1) Load model, embeddings, Y‐scaled, and scaler ─────────────────────────────\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model, E_full, Y_full_rep, tar_sc = load_model_and_data(\n",
    "        model_checkpoint=model_checkpoint,\n",
    "        params_path=params_path,\n",
    "        processed_dir=processed_dir,\n",
    "        device=device\n",
    "    )\n",
    "    # E_full: (N_proj, D_emb)\n",
    "    # Y_full_rep: (N_proj, D_tar_scaled)\n",
    "\n",
    "    # ─── 2) Reconstruct meta_rep (one row per “projection”) ───────────────────────────\n",
    "    df_meta = pd.read_csv(os.path.join(processed_dir, \"meta.csv\"))\n",
    "    projs = [1, 2, 3]\n",
    "    meta_rep = pd.concat([df_meta.assign(proj=p) for p in projs], ignore_index=True)\n",
    "    # Now meta_rep.shape[0] == E_full.shape[0] == Y_full_rep.shape[0]\n",
    "\n",
    "    N, D_emb = E_full.shape\n",
    "    D_tar = Y_full_rep.shape[1]\n",
    "    if D_tar != len(TARGET_COLS):\n",
    "        raise ValueError(f\"D_tar={D_tar} but len(TARGET_COLS)={len(TARGET_COLS)}\")\n",
    "\n",
    "    # ─── 3) Train/Test split on indices [0 .. N-1] ──────────────────────────────────\n",
    "    idx = np.arange(N)\n",
    "    idx_tmp, idx_test = train_test_split(idx, test_size=0.1, random_state=random_state)\n",
    "    val_frac = 0.1 / 0.9\n",
    "    idx_train, idx_val = train_test_split(idx_tmp, test_size=val_frac, random_state=random_state)\n",
    "\n",
    "    E_test = E_full[idx_test]              # (N_test, D_emb)\n",
    "    Y_test = Y_full_rep[idx_test]          # (N_test, D_tar_scaled)\n",
    "    meta_test = meta_rep.iloc[idx_test].reset_index(drop=True)\n",
    "\n",
    "    # ─── 4) Pick which “n_rows” test‐projections to plot ────────────────────────────\n",
    "    if select_halo_ids is not None and select_snapshots is not None:\n",
    "        if len(select_halo_ids) != len(select_snapshots):\n",
    "            raise ValueError(\"HaloIDs and Snapshots lists must match length\")\n",
    "        chosen = []\n",
    "        for hid, snap in zip(select_halo_ids, select_snapshots):\n",
    "            matches = meta_test[\n",
    "                (meta_test[\"HaloID\"] == hid) & (meta_test[\"Snapshot\"] == snap)\n",
    "            ].index\n",
    "            if len(matches) == 0:\n",
    "                raise ValueError(f\"No test entry for HaloID={hid}, Snapshot={snap}\")\n",
    "            chosen.append(int(matches[0]))\n",
    "    else:\n",
    "        rng = np.random.RandomState(random_state)\n",
    "        chosen = rng.choice(len(E_test), size=n_rows, replace=False).tolist()\n",
    "\n",
    "    n_rows = len(chosen)\n",
    "    E_chosen = E_test[chosen]             # (n_rows, D_emb)\n",
    "    Y_chosen = Y_test[chosen]             # (n_rows, D_tar_scaled)\n",
    "    meta_chosen = meta_test.iloc[chosen].reset_index(drop=True)\n",
    "\n",
    "    # ─── 5) Sample posterior & compute MAP & true‐value (physical units) ─────────────\n",
    "    post_phys = sample_posteriors(model, E_chosen, tar_sc,\n",
    "                                  n_samples=n_samples, device=device)\n",
    "    # post_phys: (n_rows, n_samples, D_tar_phys)\n",
    "\n",
    "    maps_phys = compute_map_estimates(post_phys)       # (n_rows, D_tar_phys)\n",
    "    true_phys = tar_sc.inverse_transform(Y_chosen)     # (n_rows, D_tar_phys)\n",
    "\n",
    "    # Build priors from entire test set (physical units)\n",
    "    Y_test_phys = tar_sc.inverse_transform(Y_test)     # (N_test, D_tar_phys)\n",
    "    priors = build_priors_from_training(Y_test_phys)   # list of (grid, pdf) tuples, length D_tar\n",
    "\n",
    "    # ─── 6) BEGIN PLOTTING ─────────────────────────────────────────────────────────────\n",
    "    fig, axes = plt.subplots(\n",
    "        n_rows, D_tar,\n",
    "        figsize=(3 * D_tar, 1.25 * n_rows),\n",
    "        sharex=\"col\",\n",
    "        squeeze=False\n",
    "    )\n",
    "    # Extra room at top for column titles and bottom for two‐line labels + ticks\n",
    "    plt.subplots_adjust(left=0.07, right=0.97, top=0.88, bottom=0.18, wspace=0.1, hspace=0.2)\n",
    "\n",
    "    for i_row in range(n_rows):\n",
    "        # Left‐most label (Snapshot / HaloID) with fontsize=8\n",
    "        axes[i_row, 0].text(\n",
    "            -0.15, 0.5,\n",
    "            f\"{meta_chosen['Snapshot'][i_row]}\\n{meta_chosen['HaloID'][i_row]}\",\n",
    "            transform=axes[i_row, 0].transAxes,\n",
    "            rotation=90, va=\"center\", ha=\"center\", fontsize=8\n",
    "        )\n",
    "        for d in range(D_tar):\n",
    "            ax = axes[i_row, d]\n",
    "            g_prior, pd_prior = priors[d]\n",
    "\n",
    "            # 1) Plot prior\n",
    "            ax.fill_between(g_prior, pd_prior, color=\"lightgrey\", alpha=0.6)\n",
    "            ax.plot(g_prior, pd_prior, \"k--\", lw=1)\n",
    "\n",
    "            # 2) Plot posterior KDE\n",
    "            samp = post_phys[i_row, :, d][:, None]\n",
    "            kde2 = KernelDensity(kernel=\"gaussian\", bandwidth=0.6).fit(samp)\n",
    "            g_post = np.linspace(samp.min(), samp.max(), 200)[:, None]\n",
    "            pd_post = np.exp(kde2.score_samples(g_post))\n",
    "            pd_post /= pd_post.max()\n",
    "            ax.plot(g_post.ravel(), pd_post, color=\"C0\", lw=2)\n",
    "\n",
    "            # 3) Plot MAP (gold) & truth (red)\n",
    "            ax.axvline(maps_phys[i_row, d], color=\"gold\", lw=1.5)\n",
    "            ax.axvline(true_phys[i_row, d], color=\"red\", lw=1.5)\n",
    "\n",
    "            # 4) Axes limits\n",
    "            ax.set_xlim(g_prior.min(), g_prior.max())\n",
    "            ax.set_ylim(0, None)\n",
    "\n",
    "            # 5) X‐axis: show ticks and two‐line label on last row only\n",
    "            if i_row == n_rows - 1:\n",
    "                # compute 5 evenly spaced ticks between min and max\n",
    "                tick_vals = np.linspace(g_prior.min(), g_prior.max(), 5)\n",
    "                ax.set_xticks(tick_vals)\n",
    "                ax.set_xticklabels([f\"{t:.2f}\" for t in tick_vals], fontsize=8, rotation=45)\n",
    "\n",
    "                # Two‐line label: name on first line, unit on second line\n",
    "                ax.set_xlabel(\n",
    "                    f\"{TARGET_COLS[d]}\\n({TARGET_UNITS[d]})\",\n",
    "                    fontsize=10\n",
    "                )\n",
    "            else:\n",
    "                # hide ticks and tick labels for non‐bottom rows\n",
    "                ax.set_xticks([])\n",
    "\n",
    "            # 6) Column titles on the first row, just outside via pad\n",
    "            if i_row == 0:\n",
    "                ax.set_title(\n",
    "                    TARGET_COLS[d],\n",
    "                    fontsize=10,\n",
    "                    pad=10\n",
    "                )\n",
    "\n",
    "            # 7) Hide y‐axis ticks entirely\n",
    "            ax.set_yticks([])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_checkpoint' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m plot_figure14_new_pipeline(\n\u001b[0;32m----> 2\u001b[0m     model_checkpoint\u001b[38;5;241m=\u001b[39m\u001b[43mmodel_checkpoint\u001b[49m,\n\u001b[1;32m      3\u001b[0m     params_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     processed_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocessed_data\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m     emb_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membeddings.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     fname_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilenames.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     n_rows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m,\n\u001b[1;32m      8\u001b[0m     n_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_checkpoint' is not defined"
     ]
    }
   ],
   "source": [
    "plot_figure14_new_pipeline(\n",
    "    model_checkpoint=model_checkpoint,\n",
    "    params_path=\"params.yaml\",\n",
    "    processed_dir=\"processed_data\",\n",
    "    emb_path=\"embeddings.npy\",\n",
    "    fname_path=\"filenames.npy\",\n",
    "    n_rows=15,\n",
    "    n_samples=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"experts/\"\n",
    "TARGET_COLS = [\n",
    "    'last_T_coll',\n",
    "    'last_V_coll',\n",
    "    'last_M_Crit500_coll',\n",
    "    'last_Subcluster_mass',\n",
    "    'last_Mass_ratio',\n",
    "    'last_d_peri']\n",
    "\n",
    "\n",
    "TARGET_UNITS = [\n",
    "    r'$\\mathrm{Gyr}$',                # last_T_coll\n",
    "    r'$\\mathrm{km/s}$',               # last_V_coll\n",
    "    r'$10^{14}\\,M_\\odot$',            # last_M_Crit500_coll\n",
    "    r'$10^{14}\\,M_\\odot$',            # last_Subcluster_mass\n",
    "    r'' ,                             # last_Mass_ratio (unitless)\n",
    "    r'$\\mathrm{kpc}$',                # last_d_peri        \n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_posteriors_all_targets(\n",
    "    model_checkpoint: str,\n",
    "    processed_dir: str = \"processed_data\",\n",
    "    params_path: str = \"params.yaml\",\n",
    "    n_samples_per_cluster: int = 100,\n",
    "    random_state: int = 42,\n",
    "    num_bins: int = 10,\n",
    "    max_ticks: int = 5\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot posterior-vs-truth histograms for all targets under the new embeddings→CINN→features pipeline.\n",
    "    Top of each column shows the target label; bottom x-axis shows only the unit.\n",
    "    \"\"\"\n",
    "    # ─── 1) Device ────────────────────────────────────────────────────────────────\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # ─── 2) Load model, embeddings, Y, and scaler ─────────────────────────────────\n",
    "    model, E_full, Y_full_rep, tar_sc = load_model_and_data(\n",
    "        model_checkpoint=model_checkpoint,\n",
    "        params_path=params_path,\n",
    "        processed_dir=processed_dir,\n",
    "        device=device\n",
    "    )\n",
    "    D_tar = Y_full_rep.shape[1]\n",
    "\n",
    "    # ─── 3) Build test set ─────────────────────────────────────────────────────────\n",
    "    N = len(E_full)\n",
    "    idx = np.arange(N)\n",
    "    _, idx_test = train_test_split(idx, test_size=0.1, random_state=random_state)\n",
    "\n",
    "    E_test = E_full[idx_test]\n",
    "    Y_test = Y_full_rep[idx_test]\n",
    "    Y_test_phys = tar_sc.inverse_transform(Y_test)\n",
    "\n",
    "    # ─── 4) Sample posterior draws in physical units ──────────────────────────────\n",
    "    samples_phys = sample_posteriors(\n",
    "        model,\n",
    "        E_test,\n",
    "        tar_sc,\n",
    "        n_samples=n_samples_per_cluster,\n",
    "        device=device\n",
    "    )\n",
    "    # samples_phys shape: (N_test, n_samples_per_cluster, D_tar_phys)\n",
    "\n",
    "    all_data = []\n",
    "    results = []\n",
    "\n",
    "    # ─── 5) Build 2D histograms for each target dimension ──────────────────────────\n",
    "    for d in range(D_tar):\n",
    "        gt = Y_test_phys[:, d]\n",
    "        bins = np.linspace(gt.min(), gt.max(), num_bins + 1)\n",
    "        bin_idx = np.digitize(gt, bins[1:-1], right=False)\n",
    "        bin_to_post = {b: [] for b in range(num_bins)}\n",
    "\n",
    "        for i, b in enumerate(bin_idx):\n",
    "            bin_to_post[b].append(samples_phys[i, :, d])\n",
    "\n",
    "        counts = np.zeros((num_bins, num_bins), dtype=int)\n",
    "        med_i = np.full(num_bins, np.nan)\n",
    "        lo_i = np.full(num_bins, np.nan)\n",
    "        hi_i = np.full(num_bins, np.nan)\n",
    "\n",
    "        for b in range(num_bins):\n",
    "            samples_list = bin_to_post[b]\n",
    "            if samples_list:\n",
    "                arr = np.concatenate(samples_list)\n",
    "                counts[b], _ = np.histogram(arr, bins=bins)\n",
    "                med_val = np.median(arr)\n",
    "                med_i[b] = np.clip(np.digitize(med_val, bins) - 1, 0, num_bins - 1)\n",
    "                lo_val = np.percentile(arr, 10)\n",
    "                hi_val = np.percentile(arr, 90)\n",
    "                lo_i[b] = np.clip(np.digitize(lo_val, bins) - 1, 0, num_bins - 1)\n",
    "                hi_i[b] = np.clip(np.digitize(hi_val, bins) - 1, 0, num_bins - 1)\n",
    "\n",
    "        data = counts.T\n",
    "        all_data.append(data)\n",
    "        results.append((data, med_i, lo_i, hi_i, bins))\n",
    "\n",
    "    # ─── 6) Color scale and tick positions ────────────────────────────────────────\n",
    "    flat = np.concatenate([d.flatten() for d in all_data])\n",
    "    pos = flat[flat > 0]\n",
    "    norm = LogNorm(vmin=max(1, pos.min() if pos.size else 1), vmax=flat.max())\n",
    "\n",
    "    step = max(1, num_bins // max_ticks)\n",
    "    tick_positions = np.arange(0, num_bins, step)\n",
    "    if tick_positions[-1] != num_bins - 1:\n",
    "        tick_positions = np.append(tick_positions, num_bins - 1)\n",
    "\n",
    "    # ─── 7) Create subplots: one column per target ─────────────────────────────────\n",
    "    fig, axes = plt.subplots(\n",
    "        1, D_tar,\n",
    "        figsize=(4 * D_tar, 5),\n",
    "        squeeze=False\n",
    "    )\n",
    "\n",
    "    # ─── 8) Fill each subplot ──────────────────────────────────────────────────────\n",
    "    for d, ax in enumerate(axes[0]):\n",
    "        data, med_i, lo_i, hi_i, bins = results[d]\n",
    "        ends = bins[1:]\n",
    "\n",
    "        # 8a) Show 2D histogram\n",
    "        im = ax.imshow(\n",
    "            data,\n",
    "            origin='lower',\n",
    "            norm=norm,\n",
    "            aspect='equal',\n",
    "            interpolation='nearest',\n",
    "            cmap='viridis'\n",
    "        )\n",
    "\n",
    "        # 8b) Diagonal line y=x\n",
    "        ax.plot([0, num_bins - 1], [0, num_bins - 1], color='white', linewidth=2)\n",
    "\n",
    "        # 8c) Smooth median and percentile curves\n",
    "        x_smooth = np.linspace(0, num_bins - 1, num_bins * 10)\n",
    "        ax.plot(\n",
    "            x_smooth,\n",
    "            np.interp(x_smooth, np.arange(num_bins), med_i),\n",
    "            '-', lw=3, color='black'\n",
    "        )\n",
    "        ax.plot(\n",
    "            x_smooth,\n",
    "            np.interp(x_smooth, np.arange(num_bins), lo_i),\n",
    "            '--', lw=2, color='black'\n",
    "        )\n",
    "        ax.plot(\n",
    "            x_smooth,\n",
    "            np.interp(x_smooth, np.arange(num_bins), hi_i),\n",
    "            '--', lw=2, color='black'\n",
    "        )\n",
    "\n",
    "        # 8d) Top: target label\n",
    "        ax.set_title(TARGET_COLS[d], fontsize=14, pad=10)\n",
    "\n",
    "        # 8e) X‐axis ticks: positions correspond to bin indices\n",
    "        ax.set_xticks(tick_positions)\n",
    "        ax.set_xticklabels([f'{ends[i]:.2f}' for i in tick_positions],\n",
    "                           rotation=90, fontsize=10)\n",
    "        # 8f) Bottom: show unit only\n",
    "        ax.set_xlabel(f\"{TARGET_UNITS[d]}\", fontsize=12, labelpad=8)\n",
    "\n",
    "        # 8g) Y‐axis ticks also show bin boundaries labeled by ground‐truth edges\n",
    "        ax.set_yticks(tick_positions)\n",
    "        ax.set_yticklabels([f'{ends[i]:.2f}' for i in tick_positions], fontsize=10)\n",
    "        if d == 0:\n",
    "            ax.set_ylabel('Posterior sample bin', fontsize=12)\n",
    "\n",
    "    # ─── 9) Colorbar ───────────────────────────────────────────────────────────────\n",
    "    divider = make_axes_locatable(axes[0][-1])\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "    fig.colorbar(im, cax=cax).set_label('Number of samples (log scale)', fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    #return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vera/u/jshera/CL/new_venv/lib/python3.12/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.6.1 when using version 1.6.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/vera/u/jshera/CL/new_venv/lib/python3.12/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.6.1 when using version 1.6.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num samples out of bounds: 0\n",
      "number of parameters: 1761976\n",
      "GraphINN(\n",
      "  (module_list): ModuleList(\n",
      "    (0-7): 8 x RationalQuadraticSplineBlock(\n",
      "      (softplus): Softplus(beta=0.5, threshold=20.0)\n",
      "      (subnet): Subnet(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=515, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=256, out_features=87, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vera/u/jshera/CINN_spline/representation_space/plot_utils.py:94: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(ckpt_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num samples out of bounds: 0\n",
      "number of parameters: 1761976\n",
      "GraphINN(\n",
      "  (module_list): ModuleList(\n",
      "    (0-7): 8 x RationalQuadraticSplineBlock(\n",
      "      (softplus): Softplus(beta=0.5, threshold=20.0)\n",
      "      (subnet): Subnet(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=515, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=256, out_features=87, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "num samples out of bounds: 0\n",
      "number of parameters: 1761976\n",
      "GraphINN(\n",
      "  (module_list): ModuleList(\n",
      "    (0-7): 8 x RationalQuadraticSplineBlock(\n",
      "      (softplus): Softplus(beta=0.5, threshold=20.0)\n",
      "      (subnet): Subnet(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=515, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=256, out_features=87, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "num samples out of bounds: 0\n",
      "number of parameters: 1761976\n",
      "GraphINN(\n",
      "  (module_list): ModuleList(\n",
      "    (0-7): 8 x RationalQuadraticSplineBlock(\n",
      "      (softplus): Softplus(beta=0.5, threshold=20.0)\n",
      "      (subnet): Subnet(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=515, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=256, out_features=87, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "num samples out of bounds: 0\n",
      "number of parameters: 1761976\n",
      "GraphINN(\n",
      "  (module_list): ModuleList(\n",
      "    (0-7): 8 x RationalQuadraticSplineBlock(\n",
      "      (softplus): Softplus(beta=0.5, threshold=20.0)\n",
      "      (subnet): Subnet(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=515, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=256, out_features=87, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "num samples out of bounds: 0\n",
      "number of parameters: 1761976\n",
      "GraphINN(\n",
      "  (module_list): ModuleList(\n",
      "    (0-7): 8 x RationalQuadraticSplineBlock(\n",
      "      (softplus): Softplus(beta=0.5, threshold=20.0)\n",
      "      (subnet): Subnet(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=515, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=256, out_features=87, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "num samples out of bounds: 0\n",
      "number of parameters: 1761976\n",
      "GraphINN(\n",
      "  (module_list): ModuleList(\n",
      "    (0-7): 8 x RationalQuadraticSplineBlock(\n",
      "      (softplus): Softplus(beta=0.5, threshold=20.0)\n",
      "      (subnet): Subnet(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=515, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=256, out_features=87, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "num samples out of bounds: 0\n",
      "number of parameters: 1761976\n",
      "GraphINN(\n",
      "  (module_list): ModuleList(\n",
      "    (0-7): 8 x RationalQuadraticSplineBlock(\n",
      "      (softplus): Softplus(beta=0.5, threshold=20.0)\n",
      "      (subnet): Subnet(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=515, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=256, out_features=87, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "num samples out of bounds: 0\n",
      "number of parameters: 1761976\n",
      "GraphINN(\n",
      "  (module_list): ModuleList(\n",
      "    (0-7): 8 x RationalQuadraticSplineBlock(\n",
      "      (softplus): Softplus(beta=0.5, threshold=20.0)\n",
      "      (subnet): Subnet(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=515, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=256, out_features=87, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "num samples out of bounds: 0\n",
      "number of parameters: 1761976\n",
      "GraphINN(\n",
      "  (module_list): ModuleList(\n",
      "    (0-7): 8 x RationalQuadraticSplineBlock(\n",
      "      (softplus): Softplus(beta=0.5, threshold=20.0)\n",
      "      (subnet): Subnet(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=515, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=256, out_features=87, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "num samples out of bounds: 0\n",
      "number of parameters: 1761976\n",
      "GraphINN(\n",
      "  (module_list): ModuleList(\n",
      "    (0-7): 8 x RationalQuadraticSplineBlock(\n",
      "      (softplus): Softplus(beta=0.5, threshold=20.0)\n",
      "      (subnet): Subnet(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=515, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=256, out_features=87, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "num samples out of bounds: 0\n",
      "number of parameters: 1761976\n",
      "GraphINN(\n",
      "  (module_list): ModuleList(\n",
      "    (0-7): 8 x RationalQuadraticSplineBlock(\n",
      "      (softplus): Softplus(beta=0.5, threshold=20.0)\n",
      "      (subnet): Subnet(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=515, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=256, out_features=87, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "num samples out of bounds: 0\n",
      "number of parameters: 1761976\n",
      "GraphINN(\n",
      "  (module_list): ModuleList(\n",
      "    (0-7): 8 x RationalQuadraticSplineBlock(\n",
      "      (softplus): Softplus(beta=0.5, threshold=20.0)\n",
      "      (subnet): Subnet(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=515, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=256, out_features=87, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "num samples out of bounds: 0\n",
      "number of parameters: 1761976\n",
      "GraphINN(\n",
      "  (module_list): ModuleList(\n",
      "    (0-7): 8 x RationalQuadraticSplineBlock(\n",
      "      (softplus): Softplus(beta=0.5, threshold=20.0)\n",
      "      (subnet): Subnet(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=515, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=256, out_features=87, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "num samples out of bounds: 0\n",
      "number of parameters: 1761976\n",
      "GraphINN(\n",
      "  (module_list): ModuleList(\n",
      "    (0-7): 8 x RationalQuadraticSplineBlock(\n",
      "      (softplus): Softplus(beta=0.5, threshold=20.0)\n",
      "      (subnet): Subnet(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=515, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=256, out_features=87, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "num samples out of bounds: 0\n",
      "number of parameters: 1761976\n",
      "GraphINN(\n",
      "  (module_list): ModuleList(\n",
      "    (0-7): 8 x RationalQuadraticSplineBlock(\n",
      "      (softplus): Softplus(beta=0.5, threshold=20.0)\n",
      "      (subnet): Subnet(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=515, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=256, out_features=87, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "num samples out of bounds: 0\n",
      "number of parameters: 1761976\n",
      "GraphINN(\n",
      "  (module_list): ModuleList(\n",
      "    (0-7): 8 x RationalQuadraticSplineBlock(\n",
      "      (softplus): Softplus(beta=0.5, threshold=20.0)\n",
      "      (subnet): Subnet(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=515, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=256, out_features=87, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "num samples out of bounds: 0\n",
      "number of parameters: 1761976\n",
      "GraphINN(\n",
      "  (module_list): ModuleList(\n",
      "    (0-7): 8 x RationalQuadraticSplineBlock(\n",
      "      (softplus): Softplus(beta=0.5, threshold=20.0)\n",
      "      (subnet): Subnet(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=515, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=256, out_features=87, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "num samples out of bounds: 0\n",
      "number of parameters: 1761976\n",
      "GraphINN(\n",
      "  (module_list): ModuleList(\n",
      "    (0-7): 8 x RationalQuadraticSplineBlock(\n",
      "      (softplus): Softplus(beta=0.5, threshold=20.0)\n",
      "      (subnet): Subnet(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=515, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=256, out_features=87, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "num samples out of bounds: 0\n",
      "number of parameters: 1761976\n",
      "GraphINN(\n",
      "  (module_list): ModuleList(\n",
      "    (0-7): 8 x RationalQuadraticSplineBlock(\n",
      "      (softplus): Softplus(beta=0.5, threshold=20.0)\n",
      "      (subnet): Subnet(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=515, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=256, out_features=87, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "num samples out of bounds: 0\n",
      "number of parameters: 1761976\n",
      "GraphINN(\n",
      "  (module_list): ModuleList(\n",
      "    (0-7): 8 x RationalQuadraticSplineBlock(\n",
      "      (softplus): Softplus(beta=0.5, threshold=20.0)\n",
      "      (subnet): Subnet(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=515, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=256, out_features=87, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "num samples out of bounds: 0\n",
      "number of parameters: 1761976\n",
      "GraphINN(\n",
      "  (module_list): ModuleList(\n",
      "    (0-7): 8 x RationalQuadraticSplineBlock(\n",
      "      (softplus): Softplus(beta=0.5, threshold=20.0)\n",
      "      (subnet): Subnet(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=515, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=256, out_features=87, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "num samples out of bounds: 0\n",
      "number of parameters: 1761976\n",
      "GraphINN(\n",
      "  (module_list): ModuleList(\n",
      "    (0-7): 8 x RationalQuadraticSplineBlock(\n",
      "      (softplus): Softplus(beta=0.5, threshold=20.0)\n",
      "      (subnet): Subnet(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=515, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=256, out_features=87, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "num samples out of bounds: 0\n",
      "number of parameters: 1761976\n",
      "GraphINN(\n",
      "  (module_list): ModuleList(\n",
      "    (0-7): 8 x RationalQuadraticSplineBlock(\n",
      "      (softplus): Softplus(beta=0.5, threshold=20.0)\n",
      "      (subnet): Subnet(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=515, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=256, out_features=87, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "num samples out of bounds: 0\n",
      "number of parameters: 1761976\n",
      "GraphINN(\n",
      "  (module_list): ModuleList(\n",
      "    (0-7): 8 x RationalQuadraticSplineBlock(\n",
      "      (softplus): Softplus(beta=0.5, threshold=20.0)\n",
      "      (subnet): Subnet(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=515, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=256, out_features=87, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "num samples out of bounds: 0\n",
      "number of parameters: 1761976\n",
      "GraphINN(\n",
      "  (module_list): ModuleList(\n",
      "    (0-7): 8 x RationalQuadraticSplineBlock(\n",
      "      (softplus): Softplus(beta=0.5, threshold=20.0)\n",
      "      (subnet): Subnet(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=515, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=256, out_features=87, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "num samples out of bounds: 0\n",
      "number of parameters: 1761976\n",
      "GraphINN(\n",
      "  (module_list): ModuleList(\n",
      "    (0-7): 8 x RationalQuadraticSplineBlock(\n",
      "      (softplus): Softplus(beta=0.5, threshold=20.0)\n",
      "      (subnet): Subnet(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=515, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=256, out_features=87, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "num samples out of bounds: 0\n",
      "number of parameters: 1761976\n",
      "GraphINN(\n",
      "  (module_list): ModuleList(\n",
      "    (0-7): 8 x RationalQuadraticSplineBlock(\n",
      "      (softplus): Softplus(beta=0.5, threshold=20.0)\n",
      "      (subnet): Subnet(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=515, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=256, out_features=87, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "num samples out of bounds: 0\n",
      "number of parameters: 1761976\n",
      "GraphINN(\n",
      "  (module_list): ModuleList(\n",
      "    (0-7): 8 x RationalQuadraticSplineBlock(\n",
      "      (softplus): Softplus(beta=0.5, threshold=20.0)\n",
      "      (subnet): Subnet(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=515, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=256, out_features=87, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "num samples out of bounds: 0\n",
      "number of parameters: 1761976\n",
      "GraphINN(\n",
      "  (module_list): ModuleList(\n",
      "    (0-7): 8 x RationalQuadraticSplineBlock(\n",
      "      (softplus): Softplus(beta=0.5, threshold=20.0)\n",
      "      (subnet): Subnet(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=515, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=256, out_features=87, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "num samples out of bounds: 0\n",
      "number of parameters: 1761976\n",
      "GraphINN(\n",
      "  (module_list): ModuleList(\n",
      "    (0-7): 8 x RationalQuadraticSplineBlock(\n",
      "      (softplus): Softplus(beta=0.5, threshold=20.0)\n",
      "      (subnet): Subnet(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=515, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=256, out_features=87, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "num samples out of bounds: 0\n",
      "number of parameters: 1761976\n",
      "GraphINN(\n",
      "  (module_list): ModuleList(\n",
      "    (0-7): 8 x RationalQuadraticSplineBlock(\n",
      "      (softplus): Softplus(beta=0.5, threshold=20.0)\n",
      "      (subnet): Subnet(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=515, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=256, out_features=87, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "num samples out of bounds: 0\n",
      "number of parameters: 1761976\n",
      "GraphINN(\n",
      "  (module_list): ModuleList(\n",
      "    (0-7): 8 x RationalQuadraticSplineBlock(\n",
      "      (softplus): Softplus(beta=0.5, threshold=20.0)\n",
      "      (subnet): Subnet(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=515, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=256, out_features=87, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "num samples out of bounds: 0\n",
      "number of parameters: 1761976\n",
      "GraphINN(\n",
      "  (module_list): ModuleList(\n",
      "    (0-7): 8 x RationalQuadraticSplineBlock(\n",
      "      (softplus): Softplus(beta=0.5, threshold=20.0)\n",
      "      (subnet): Subnet(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=515, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=256, out_features=87, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "num samples out of bounds: 0\n",
      "number of parameters: 1761976\n",
      "GraphINN(\n",
      "  (module_list): ModuleList(\n",
      "    (0-7): 8 x RationalQuadraticSplineBlock(\n",
      "      (softplus): Softplus(beta=0.5, threshold=20.0)\n",
      "      (subnet): Subnet(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=515, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=256, out_features=87, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "num samples out of bounds: 0\n",
      "number of parameters: 1761976\n",
      "GraphINN(\n",
      "  (module_list): ModuleList(\n",
      "    (0-7): 8 x RationalQuadraticSplineBlock(\n",
      "      (softplus): Softplus(beta=0.5, threshold=20.0)\n",
      "      (subnet): Subnet(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=515, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=256, out_features=87, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "num samples out of bounds: 0\n",
      "number of parameters: 1761976\n",
      "GraphINN(\n",
      "  (module_list): ModuleList(\n",
      "    (0-7): 8 x RationalQuadraticSplineBlock(\n",
      "      (softplus): Softplus(beta=0.5, threshold=20.0)\n",
      "      (subnet): Subnet(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=515, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=256, out_features=87, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "num samples out of bounds: 0\n",
      "number of parameters: 1761976\n",
      "GraphINN(\n",
      "  (module_list): ModuleList(\n",
      "    (0-7): 8 x RationalQuadraticSplineBlock(\n",
      "      (softplus): Softplus(beta=0.5, threshold=20.0)\n",
      "      (subnet): Subnet(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=515, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=256, out_features=87, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "num samples out of bounds: 0\n",
      "number of parameters: 1761976\n",
      "GraphINN(\n",
      "  (module_list): ModuleList(\n",
      "    (0-7): 8 x RationalQuadraticSplineBlock(\n",
      "      (softplus): Softplus(beta=0.5, threshold=20.0)\n",
      "      (subnet): Subnet(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=515, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=256, out_features=87, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "num samples out of bounds: 0\n",
      "number of parameters: 1761976\n",
      "GraphINN(\n",
      "  (module_list): ModuleList(\n",
      "    (0-7): 8 x RationalQuadraticSplineBlock(\n",
      "      (softplus): Softplus(beta=0.5, threshold=20.0)\n",
      "      (subnet): Subnet(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=515, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=256, out_features=87, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "num samples out of bounds: 0\n",
      "number of parameters: 1761976\n",
      "GraphINN(\n",
      "  (module_list): ModuleList(\n",
      "    (0-7): 8 x RationalQuadraticSplineBlock(\n",
      "      (softplus): Softplus(beta=0.5, threshold=20.0)\n",
      "      (subnet): Subnet(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=515, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=256, out_features=87, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "num samples out of bounds: 0\n",
      "number of parameters: 1761976\n",
      "GraphINN(\n",
      "  (module_list): ModuleList(\n",
      "    (0-7): 8 x RationalQuadraticSplineBlock(\n",
      "      (softplus): Softplus(beta=0.5, threshold=20.0)\n",
      "      (subnet): Subnet(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=515, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=256, out_features=87, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "num samples out of bounds: 0\n",
      "number of parameters: 1761976\n",
      "GraphINN(\n",
      "  (module_list): ModuleList(\n",
      "    (0-7): 8 x RationalQuadraticSplineBlock(\n",
      "      (softplus): Softplus(beta=0.5, threshold=20.0)\n",
      "      (subnet): Subnet(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=515, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=256, out_features=87, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "num samples out of bounds: 0\n",
      "number of parameters: 1761976\n",
      "GraphINN(\n",
      "  (module_list): ModuleList(\n",
      "    (0-7): 8 x RationalQuadraticSplineBlock(\n",
      "      (softplus): Softplus(beta=0.5, threshold=20.0)\n",
      "      (subnet): Subnet(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=515, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=256, out_features=87, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "num samples out of bounds: 0\n",
      "number of parameters: 1761976\n",
      "GraphINN(\n",
      "  (module_list): ModuleList(\n",
      "    (0-7): 8 x RationalQuadraticSplineBlock(\n",
      "      (softplus): Softplus(beta=0.5, threshold=20.0)\n",
      "      (subnet): Subnet(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=515, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=256, out_features=87, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "num samples out of bounds: 0\n",
      "number of parameters: 1761976\n",
      "GraphINN(\n",
      "  (module_list): ModuleList(\n",
      "    (0-7): 8 x RationalQuadraticSplineBlock(\n",
      "      (softplus): Softplus(beta=0.5, threshold=20.0)\n",
      "      (subnet): Subnet(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=515, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=256, out_features=87, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "num samples out of bounds: 0\n",
      "number of parameters: 1761976\n",
      "GraphINN(\n",
      "  (module_list): ModuleList(\n",
      "    (0-7): 8 x RationalQuadraticSplineBlock(\n",
      "      (softplus): Softplus(beta=0.5, threshold=20.0)\n",
      "      (subnet): Subnet(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=515, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=256, out_features=87, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "num samples out of bounds: 0\n",
      "number of parameters: 1761976\n",
      "GraphINN(\n",
      "  (module_list): ModuleList(\n",
      "    (0-7): 8 x RationalQuadraticSplineBlock(\n",
      "      (softplus): Softplus(beta=0.5, threshold=20.0)\n",
      "      (subnet): Subnet(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=515, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=256, out_features=87, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "num samples out of bounds: 0\n",
      "number of parameters: 1761976\n",
      "GraphINN(\n",
      "  (module_list): ModuleList(\n",
      "    (0-7): 8 x RationalQuadraticSplineBlock(\n",
      "      (softplus): Softplus(beta=0.5, threshold=20.0)\n",
      "      (subnet): Subnet(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=515, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=256, out_features=87, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "num samples out of bounds: 0\n",
      "number of parameters: 1761976\n",
      "GraphINN(\n",
      "  (module_list): ModuleList(\n",
      "    (0-7): 8 x RationalQuadraticSplineBlock(\n",
      "      (softplus): Softplus(beta=0.5, threshold=20.0)\n",
      "      (subnet): Subnet(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=515, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=256, out_features=87, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplot_posteriors_all_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprocessed_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprocessed_data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparams.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples_per_cluster\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_bins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_ticks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 36\u001b[0m, in \u001b[0;36mplot_posteriors_all_targets\u001b[0;34m(model_checkpoint, processed_dir, params_path, n_samples_per_cluster, random_state, num_bins, max_ticks)\u001b[0m\n\u001b[1;32m     33\u001b[0m Y_test_phys \u001b[38;5;241m=\u001b[39m tar_sc\u001b[38;5;241m.\u001b[39minverse_transform(Y_test)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# ─── 4) Sample posterior draws in physical units ──────────────────────────────\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m samples_phys \u001b[38;5;241m=\u001b[39m \u001b[43msample_posteriors\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mE_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtar_sc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_per_cluster\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# samples_phys shape: (N_test, n_samples_per_cluster, D_tar_phys)\u001b[39;00m\n\u001b[1;32m     45\u001b[0m all_data \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/vera/u/jshera/CINN_spline/representation_space/plot_utils.py:121\u001b[0m, in \u001b[0;36msample_posteriors\u001b[0;34m(model, embeddings, scaler, n_samples, device)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;124;03mSupports both a unified model and MoE router function.\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(model):  \u001b[38;5;66;03m# MoE\u001b[39;00m\n\u001b[0;32m--> 121\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# unified\u001b[39;00m\n\u001b[1;32m    123\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m/vera/u/jshera/CINN_spline/representation_space/plot_utils.py:109\u001b[0m, in \u001b[0;36mload_model_and_data.<locals>.expert_router_model\u001b[0;34m(x, n_samples)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo model found for expert \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpert_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 109\u001b[0m         sample_i \u001b[38;5;241m=\u001b[39m \u001b[43mexpert\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (1, n_samples, D)\u001b[39;00m\n\u001b[1;32m    110\u001b[0m         all_samples\u001b[38;5;241m.\u001b[39mappend(sample_i)\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(all_samples, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/vera/u/jshera/CINN_spline/representation_space/model.py:694\u001b[0m, in \u001b[0;36mCINN.sample\u001b[0;34m(self, num_pts, condition)\u001b[0m\n\u001b[1;32m    690\u001b[0m z \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnormal(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    691\u001b[0m     size\u001b[38;5;241m=\u001b[39m(num_pts\u001b[38;5;241m*\u001b[39mcondition\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_dim),\n\u001b[1;32m    692\u001b[0m     device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters())\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    693\u001b[0m c \u001b[38;5;241m=\u001b[39m condition\u001b[38;5;241m.\u001b[39mrepeat(num_pts,\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 694\u001b[0m x, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrev\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mreshape(num_pts, condition\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_dim)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m/vera/u/jshera/CINN_spline/representation_space/model.py:497\u001b[0m, in \u001b[0;36mCINN.forward\u001b[0;34m(self, x, c, rev, jac)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_subnet:\n\u001b[1;32m    496\u001b[0m     c_norm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_subnet(c_norm)\n\u001b[0;32m--> 497\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrev\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjac\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vera/u/jshera/CL/new_venv/lib/python3.12/site-packages/FrEIA/framework/graph_inn.py:298\u001b[0m, in \u001b[0;36mGraphINN.forward\u001b[0;34m(self, x_or_z, c, rev, jac, intermediate_outputs, x)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_condition:\n\u001b[0;32m--> 298\u001b[0m         mod_out \u001b[38;5;241m=\u001b[39m \u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmod_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrev\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjac\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    300\u001b[0m         mod_out \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mmodule(mod_in, rev\u001b[38;5;241m=\u001b[39mrev, jac\u001b[38;5;241m=\u001b[39mjac)\n",
      "File \u001b[0;32m/vera/u/jshera/CL/new_venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vera/u/jshera/CL/new_venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/vera/u/jshera/CINN_spline/representation_space/model.py:441\u001b[0m, in \u001b[0;36mRationalQuadraticSplineBlock.forward\u001b[0;34m(self, x, c, rev, jac)\u001b[0m\n\u001b[1;32m    439\u001b[0m     x2, j2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unconstrained_rational_quadratic_spline(x2, theta, rev\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 441\u001b[0m     theta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1c\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(x1c\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplits[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m3\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_bins \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    442\u001b[0m     x2, j2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unconstrained_rational_quadratic_spline(x2, theta, rev\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    443\u001b[0m log_jac_det \u001b[38;5;241m=\u001b[39m j2\n",
      "File \u001b[0;32m/vera/u/jshera/CL/new_venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vera/u/jshera/CL/new_venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/vera/u/jshera/CINN_spline/representation_space/model.py:127\u001b[0m, in \u001b[0;36mSubnet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vera/u/jshera/CL/new_venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vera/u/jshera/CL/new_venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/vera/u/jshera/CL/new_venv/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/vera/u/jshera/CL/new_venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/vera/u/jshera/CL/new_venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/vera/u/jshera/CL/new_venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "plot_posteriors_all_targets(\n",
    "    model_checkpoint=model_checkpoint,\n",
    "    processed_dir=\"processed_data\",\n",
    "    params_path=\"params.yaml\",\n",
    "    n_samples_per_cluster=1000,\n",
    "    random_state=42,\n",
    "    num_bins=10,\n",
    "    max_ticks=5\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (new_venv)",
   "language": "python",
   "name": "new_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
